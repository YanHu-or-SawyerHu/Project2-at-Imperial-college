{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import element\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abbreviations import schwartz_hearst\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/rdsgpfs/general/user/yh4218/home/data/NLP-MWAS'\n",
    "file_list = []\n",
    "def get_files(base_dir,file_list):\n",
    "    files = os.listdir(base_dir)\n",
    "    for i in files:\n",
    "        abs_path = os.path.join(base_dir,i)\n",
    "        if re.match(r'(.*)PMC(.*).html',abs_path):\n",
    "            file_list.append(abs_path)\n",
    "        elif os.path.isdir(abs_path)&('ipynb_checkpoints' not in abs_path):\n",
    "            get_files(abs_path,file_list)\n",
    "    return file_list\n",
    "\n",
    "file_list = get_files(base_dir,file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_list=['funding',\n",
    "              'Conflicts of Interest',\n",
    "              #'Additional Information',\n",
    "              'Acknowledgment',\n",
    "              'Acknowledgement',\n",
    "              'Acknoweldgements',\n",
    "              'financial',\n",
    "              'contribution',\n",
    "              'conflict',\n",
    "              'footnotes',\n",
    "              'interest',\n",
    "              'Reference',\n",
    "              'Formats',\n",
    "              'Share',\n",
    "              'Patent',\n",
    "              'disclosure',\n",
    "              'Availability',\n",
    "              'additional']\n",
    "abstract_list=['abstract']\n",
    "introduction_list=['introduction']\n",
    "background_list=['background']\n",
    "overview_list=['overview']\n",
    "supplementary_material_list=['supplementary','Associated Data','Supplemental']\n",
    "abbreviation_list=['glossary','abbreviation']\n",
    "method_material_list=['method','material','Experimental'] # sometimes titled as Experimental section & procedure \n",
    "result_discussion_list=['Results','discussion'] # sometimes with future direction\n",
    "conclusion_list=['conclusion']  # sometimes with future direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get particular para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_particular_para(soup_og,file_name):\n",
    "    #text_to_write=file_name+'\\n'\n",
    "    text_to_write=''\n",
    "    heading_text_list=[]\n",
    "    paragraphs = soup_og.find_all('p',attrs={'id': re.compile('(__|_|)(p|P|Par|par|idm|para)\\d+')})\n",
    "    for number, paragraph in enumerate(paragraphs):\n",
    "        previous_h2 =  paragraph.find_previous('h2')\n",
    "        if previous_h2:\n",
    "            heading_text = previous_h2.get_text()\n",
    "            if not any(discard_word.lower() in heading_text.lower() for discard_word in discard_list):\n",
    "                \n",
    "                # abstract_list\n",
    "                if any(abstract_word.lower() in heading_text.lower() for abstract_word in abstract_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/abstract/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "                        \n",
    "                # introduction_list\n",
    "                if any(introduction_word.lower() in heading_text.lower() for introduction_word in introduction_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/introduction/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "\n",
    "                # background_list\n",
    "                if any(background_word.lower() in heading_text.lower() for background_word in background_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/background/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "                        \n",
    "                # overview_list\n",
    "                if any(overview_word.lower() in heading_text.lower() for overview_word in overview_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/overview/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "                        \n",
    "                # supplementary_material_list\n",
    "                if any(supplementary_material_word.lower() in heading_text.lower() for supplementary_material_word in supplementary_material_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/supplementary_material/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "                        \n",
    "                # method_material_list\n",
    "                if any(method_material_word.lower() in heading_text.lower() for method_material_word in method_material_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/method_material/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "                        \n",
    "                # result_discussion_list\n",
    "                if any(result_discussion_word.lower() in heading_text.lower() for result_discussion_word in result_discussion_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/result_discussion/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "                        \n",
    "                # conclusion_list\n",
    "                if any(conclusion_word.lower() in heading_text.lower() for conclusion_word in conclusion_list):\n",
    "                    text_to_write+=paragraph.get_text()+'\\n'\n",
    "                    with open('/rdsgpfs/general/user/yh4218/home/outputs/classified section/conclusion/'+file.split('/')[-1].replace('.html','.txt'),'w') as f:\n",
    "                        f.write(text_to_write)\n",
    "                        \n",
    "                        \n",
    "    return text_to_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_text=''\n",
    "for file in file_list:\n",
    "    with open(file,'r',encoding='UTF-8',errors='ignore') as f:\n",
    "        text = f.read()\n",
    "        soup = BeautifulSoup(text, 'html.parser')\n",
    "        text_to_write=extract_particular_para(soup,file)\n",
    "        #whole_text+=text_to_write+'\\n'\n",
    "        #with open('/rdsgpfs/general/user/yh4218/home/outputs/classfication/abstract/'+file.split('/')[-1].replace('.html','.txt'),'w') as abstract_file:\n",
    "        #    abstract_file.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
