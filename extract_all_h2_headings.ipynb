{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(base_dir,file_list):\n",
    "    files = os.listdir(base_dir)\n",
    "    for i in files:\n",
    "        abs_path = os.path.join(base_dir,i)\n",
    "        if re.match(r'(.*)PMC(.*).html',abs_path) and ('highlighted' not in abs_path):\n",
    "            file_list.append(abs_path)\n",
    "        elif os.path.isdir(abs_path)&('ipynb_checkpoints' not in abs_path):\n",
    "            get_files(abs_path,file_list)\n",
    "    return file_list\n",
    "\n",
    "def extract_all_h2_headings(file_list_without_duplicates):\n",
    "    heading_text_list=[]\n",
    "    heading_text_list_with_filename=[]\n",
    "    for file in file_list_without_duplicates:\n",
    "        with open(file,'r',encoding='UTF-8',errors='ignore') as f:\n",
    "            text = f.read()\n",
    "            soup = BeautifulSoup(text, 'html.parser')\n",
    "            headings = soup.find_all('h2')\n",
    "            for number, heading in enumerate(headings):\n",
    "                heading_text =  heading.get_text()\n",
    "                \n",
    "                # [heading starts with \"1.\",heading starts with \"P1\"]\n",
    "                pattern_list=['^(([0-9]\\. *)+)','^(P[0-9])','^([0-9]) ']\n",
    "                pattern_status=False\n",
    "                for pattern in pattern_list:\n",
    "                    if re.search(pattern,heading_text):\n",
    "                        pattern_status=True\n",
    "                        heading_text_list.append(heading_text.strip(re.search(pattern,heading_text).group()))\n",
    "                        heading_text_list_with_filename.append(heading_text.strip(re.search(pattern,heading_text).group())+'thereisaspace'+file.split('/')[-1])\n",
    "\n",
    "                if not pattern_status:\n",
    "                    heading_text_list.append(heading_text)\n",
    "                    heading_text_list_with_filename.append(heading_text+'thereisaspace'+file.split('/')[-1])\n",
    "                \n",
    "    heading_text_list_tmp=[i.lower().strip('.').strip(' ').strip(':').strip(' ').strip('*').strip(':').replace('\\n',' ') for i in heading_text_list]\n",
    "    heading_text_list = heading_text_list_tmp\n",
    "    heading_text_list_with_filename_tmp=[i.lower().strip('.').strip(' ').strip(':').strip(' ').strip('*').strip(':').replace('\\n',' ') for i in heading_text_list_with_filename ]\n",
    "    heading_text_list_with_filename=heading_text_list_with_filename_tmp\n",
    "    return heading_text_list, heading_text_list_with_filename\n",
    "\n",
    "\n",
    "def keep_count_unique_heading(heading_text_list):\n",
    "    heading_text_list_unique=[]\n",
    "    heading_text_list_unique_for_count=[]\n",
    "    for number,heading in enumerate(heading_text_list):\n",
    "        number_of_heading = heading_text_list.count(heading)\n",
    "        if number_of_heading >1 and heading_text_list_unique_for_count.count(heading)<1: \n",
    "            heading_text_list_unique.append(heading_text_list_with_filename[number]+'\\t'+str(number_of_heading))\n",
    "            heading_text_list_unique_for_count.append(heading)\n",
    "    return heading_text_list_unique, heading_text_list_unique_for_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input base directory: /rdsgpfs/general/user/yh4218/home/data/NLP\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    base_dir = input('Input base directory:')\n",
    "    file_list = []\n",
    "    file_list = get_files(base_dir,file_list)\n",
    "    file_list_without_duplicates=[]\n",
    "    for file in file_list:\n",
    "        PMC_number=file.split('/')[-1]\n",
    "        duplicates_status=False\n",
    "        for f in file_list_without_duplicates:\n",
    "            if PMC_number in f:\n",
    "                duplicates_status=True\n",
    "        if not duplicates_status:\n",
    "            file_list_without_duplicates.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    heading_text_list, heading_text_list_with_filename = extract_all_h2_headings(file_list_without_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    heading_text_list_unique, heading_text_list_unique_for_count = keep_count_unique_heading(heading_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open('/rdsgpfs/general/user/yh4218/home/data/all_unique_h2_headings_with_counts.txt','w') as f:\n",
    "        for heading in heading_text_list_unique:\n",
    "            f.write(str(heading)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
